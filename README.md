# NexaChat â€“ Lightweight LLM Chatbot

## ğŸ“Œ Overview

This project allows you to upload PDFs, extract text, convert it into embeddings using Ollama's Embedding Model, and store them in a Milvus vector database. You can then perform semantic searches and AI Chat on the stored text.

ğŸ”— [Full System Design Notion Write-up](https://desert-burst-2c1.notion.site/NexaChat-Lightweight-LLM-Chatbot-1d03ae4e7994808b8482e52ed88b375b?pvs=4)

## ğŸ—ï¸ Project Structure

```
app/
â”‚-- models/               # Pretrained embedding model and Large Language Models
â”‚-- uploads/              # Directory for uploaded PDF files
â”‚-- main.py               # Main Streamlit app
â”‚-- requirements.txt      # Dependencies
â”‚-- Dockerfile            # Docker container setup
â”‚-- .dockerignore         # Files to exclude from Docker image
â”‚-- README.md             # Project documentation
```

## âš™ï¸ Installation

### Prerequisites

- Python 3.8+
- Ollama application
- Milvus installed and running (Preferable in Docker)
- Docker (if using containerization)

### Setup

1. Clone the repository:
   ```sh
   git clone <repo_url>
   cd app
   ```
2. Install Ollama
3. Pull Ollama LLM Model:
   ```sh
   ollama pull gemma3
   ```
4. Pull Ollama Embedding Model:
   ```sh
   ollama pull nomic-embed-text
   ```
5. Create and activate a virtual environment:
   ```sh
   python -m venv venv
   source venv/bin/activate  # On Windows use: venv\Scripts\activate
   ```
6. Install dependencies:
   ```sh
   pip install -r requirements.txt
   ```

## ğŸš€ Usage

### Run Locally

1. Start Milvus:
   ```sh
   docker run -d --name milvus-standalone -p 19530:19530 milvusdb/milvus:latest
   ```
2. Run the Streamlit app:
   ```sh
   streamlit run src/app_v3.py -- --host "replace_with_milvus_host_ip" --port "19530" --ollama_model "gemma3"
   ```

### Run with Docker

1. Build the Docker image:
   ```sh
   docker build -t pdf-milvus-app .
   ```
2. Run the container:
   ```sh
   docker run --network my-network -p 8501:8501 pdf-milvus-app-new -- --host "replace_with_milvus_host_ip" --port "19530" --ollama_model "gemma3"
   ```

## ğŸ“‚ Features

- Upload PDFs and extract text
- Chunk text using LangChain
- Convert text into embeddings with Sentence Transformers
- Store embeddings in Milvus
- Perform semantic search on stored PDF content

## ğŸ¤– Model Used

- `all-MiniLM-L6-v2` from `sentence-transformers`
- `gemma3` from `ollama`

## ğŸ› ï¸ Troubleshooting

- Ensure Milvus is running before starting the app.
- If running in a restricted environment, download the model manually and place it in `models/`.

## ğŸ“œ License

This project is licensed under the MIT License.